{
  "title": "ChatGPT",
  "slug": "chatgpt",
  "extract": "ChatGPT is a generative artificial intelligence chatbot developed by OpenAI, and released in November 2022. It uses generative pre-trained transformers (GPTs), such as GPT-5, to generate text, speech, and images in response to user prompts. It is credited with accelerating the AI boom, an ongoing period marked by rapid investment and public attention toward the field of artificial intelligence (AI). OpenAI operates the service on a freemium model. Users can interact with ChatGPT through text, audio, and image prompts.\nThe service gained 100 million users in two months, making it the fastest-growing consumer software application in history. ChatGPT's website is among the top 5 most-visited websites globally. It has been lauded for its potential to transform numerous professional fields, and instigated public debate about the nature of creativity and the future of knowledge work.\nThe chatbot has also been criticized for its limitations and potential for unethical use. It can generate plausible-sounding but incorrect or nonsensical answers, known as hallucinations. Biases in its training data have been reflected in its responses. The chatbot can facilitate academic dishonesty, generate misinformation, and create malicious code. The ethics of its development, particularly the use of copyrighted content as training data, have also drawn controversy.\n\n\nTraining\n\nChatGPT is based on GPT foundation models that have been fine-tuned for conversational assistance. The fine-tuning process involved supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers acted as both the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses generated by the model in previous conversations. These rankings were used to create \"reward models\" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\nTo build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers, earning around $1.32 to $2 per hour, to label such content. These labels were used to train a model to detect such content in the future. The laborers were exposed to toxic and traumatic content; one worker described the assignment as \"torture\". OpenAI's outsourcing partner was Sama, a training-data company based in San Francisco, California.\nOpenAI collects data from ChatGPT users to further train and fine-tune its services. Users can upvote or downvote responses they receive from ChatGPT, and can fill in a text field with additional feedback.\nChatGPT's training data includes software manual pages, information about internet phenomena such as bulletin board systems, multiple programming languages, and the text of Wikipedia.\n\n\nFeatures\nChatGPT is a chatbot and AI assistant built on large language model (LLM) technology. It is designed to generate human-like text and can carry out a wide variety of tasks. These include, among many others, writing and debugging computer programs, composing music, scripts, fairy tales, and essays, answering questions (sometimes at a level exceeding that of an average human test-taker), and generating business concepts.\nChatGPT is frequently used for translation and summarization tasks, and can simulate interactive environments such as a Linux terminal, a multi-user chat room, or simple text-based games such as tic-tac-toe.\nUsers interact with ChatGPT through conversations which consist of text, audio, and image inputs and outputs. The user's inputs to these conversations are referred to as prompts. An optional \"Memory\" feature allows users to tell ChatGPT to memorize specific information. Another option allows ChatGPT to recall old conversations. GPT-based moderation classifiers are used to reduce the risk of harmful outputs being presented to users.\nIn March 2023, OpenAI added support for plugins for ChatGPT. This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack, and Wolfram.\nIn October 2024, ChatGPT Search was introduced. It allows ChatGPT to search the web in an attempt to make more accurate and up-to-date responses.\nIn December 2024, OpenAI launched a new feature allowing users to call ChatGPT with a telephone for up to 15 minutes per month for free.\nIn September 2025, OpenAI added a feature called Pulse, which generates a daily analysis of a user's chats and connected apps such as Gmail and Google Calendar.\nIn October 2025, OpenAI launched ChatGPT Atlas, a browser integrating the ChatGPT assistant directly into web navigation, to compete with existing browsers such as Google Chrome and Safari. It has an additional feature called \"agentic mode\" that allows it to take online actions for the user.\n\n\nPaid tier\nChatGPT was initially free to the public and remains free in a limited capacity. In February 2023, OpenAI launched a premium service, ChatGPT Plus, that costs US$20 per month. According to the company, Plus provided access during peak periods, no downtime, priority access to new features, and faster response speeds. OpenAI later introduced the subscription plans \"ChatGPT Team\" and \"ChatGPT Enterprise\". What was offered on the paid plan versus the free tier changed as OpenAI has continued to update ChatGPT, and a Pro tier at $200/mo was introduced in December 2024. The Pro launch coincided with the release of the o1 model. In August 2025, ChatGPT Go was offered in India for ₹399 per month. The plan has higher limits than the free version.\n\n\nMobile apps\nIn May-July 2023, OpenAI began offering ChatGPT iOS and Android apps. ChatGPT can also power Android's assistant.\nAn app for Windows launched on the Microsoft Store on October 15, 2024.\n\n\nInfrastructure\nChatGPT initially used a Microsoft Azure infrastructure which was powered by a supercomputer that Microsoft built specifically for OpenAI, equipped with thousands of GPUs manufactured by Nvidia, costing hundreds of millions of dollars. Following ChatGPT's success, Microsoft upgraded the OpenAI infrastructure in 2023. TrendForce estimated that 30,000 Nvidia GPUs (each costing approximately $10,000–15,000) were used to power ChatGPT in 2023.\nScientists at the University of California, Riverside, estimated in 2023 that a series of 5 to 50 prompts to ChatGPT needs approximately 0.5 liters (0.11 imp gal; 0.13 U.S. gal) of water for Microsoft servers' cooling.\n\n\nLanguages\nOpenAI met Icelandic President Guðni Th. Jóhannesson in 2022. In 2023, OpenAI worked with a team of 40 Icelandic volunteers to fine-tune ChatGPT's Icelandic conversation skills as a part of Iceland's attempts to preserve the Icelandic language.\nChatGPT (based on GPT-4) was better able to translate Japanese to English when compared to Bing, Bard, and DeepL Translator in 2023. Researchers suggested this was due to its higher ability to capture the context.\nIn December 2023, the Albanian government decided to use ChatGPT for the rapid translation of European Union documents and the analysis of required changes needed for Albania's accession to the EU.\nSeveral studies have shown that ChatGPT can outperform Google Translate in some mainstream translation tasks. However, no machine translation services match human expert performance.\nIn August 2024, a representative of the Asia Pacific wing of OpenAI made a visit to Taiwan, during which a demonstration of ChatGPT's Chinese abilities was made. ChatGPT's Mandarin Chinese abilities were lauded, but the ability of the AI to produce content in Mandarin Chinese in a Taiwanese accent was found to be \"less than ideal\" due to differences between mainland Mandarin Chinese and Taiwanese Mandarin.\n\n\nGPT Store\n\nIn November 2023, OpenAI released GPT Builder a tool for users to customize ChatGPT's behavior for a specific use case. The customized systems are referred to as GPTs. In January 2024, OpenAI launched the GPT Store, a marketplace for GPTs. At launch, OpenAI included more than 3 million GPTs created by GPT Builder users in the GPT Store.\n\n\nDeep Research\n\nIn February 2025, OpenAI released Deep Research. According to TechCrunch, it is a service based on o3 that combines advanced reasoning and web search capabilities to make comprehensive reports within 5 to 30 minutes.\n\n\nImages\nIn October 2023, OpenAI's image generation model DALL-E 3 was integrated into ChatGPT. The integration used ChatGPT to write prompts for DALL-E guided by conversations with users.\nIn March 2025, OpenAI updated ChatGPT to generate images using GPT Image instead of DALL-E. One of the most significant improvements was in the generation of text within images, which is especially useful for branded content. However, this ability is noticeably worse in non-Latin alphabets. The model can also generate new images based on existing ones provided in the prompt. These images are generated with C2PA metadata, which can be used to verify that they are AI-generated. OpenAI has emplaced additional safeguards to prevent what the company deems to be harmful image generation.\n\n\nAgents\nIn 2025, OpenAI added several features to make ChatGPT more agentic (capable of autonomously performing longer tasks). In January, Operator was released. It was capable of autonomously performing tasks through web browser interactions, including filling forms, placing online orders, scheduling appointments, and other browser-based tasks. It was controlling a software environment inside a virtual machine with limited internet connectivity and with safety restrictions. It struggled with complex user interfaces.\nIn May 2025, OpenAI introduced an agent for coding named Codex. It is capable of writing software, answering codebase questions, running tests, and proposing pull requests. It is based on a fine-tuned version of OpenAI o3. It has two versions, one running in a virtual machine in the cloud, and one where the agent runs in the cloud, but performs actions on a local machine connected via API.\nIn July 2025, OpenAI released ChatGPT agent, an AI agent that can perform multi-step tasks. Like Operator, it controls a virtual computer. It also inherits from Deep Research's ability to gather and summarize significant volumes of information. The user can interrupt tasks or provide additional instructions as needed.\nIn September 2025, OpenAI partnered with Stripe, Inc. to release Agentic Commerce Protocol, enabling purchases through ChatGPT. At launch, the feature was limited to purchases on Etsy from US users with a payment method linked to their OpenAI account. OpenAI takes an undisclosed cut from the merchant's payment.\n\n\nLimitations\nChatGPT's training data only covers a period up to the cut-off date, so it lacks knowledge of recent events. OpenAI has sometimes mitigated this effect by updating the training data. ChatGPT can find more up-to-date information by searching the web, but this doesn't ensure that responses are accurate, as it may access unreliable or misleading websites.\nTraining data also suffers from algorithmic bias. The reward model of ChatGPT, designed around human oversight, can be over-optimized and thus hinder performance, in an example of an optimization pathology known as Goodhart's law. These limitations may be revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT generated a rap in which women and scientists of color were asserted to be inferior to white male scientists.\n\n\nHallucination\n\nNonsense and misinformation presented as fact by ChatGPT and other LLMs is often called hallucination. A 2023 analysis estimated that ChatGPT hallucinates around 3% of the time. The term \"hallucination\" as applied to LLMs is distinct from its meaning in psychology, and the phenomenon in chatbots is more similar to confabulation or bullshitting.\nJournalists and scholars have commented on ChatGPT's tendency to output false information. When CNBC asked ChatGPT for the lyrics to \"Ballad of Dwight Fry\", ChatGPT supplied invented lyrics rather than the actual lyrics.\n\n\nJailbreaking\n\nChatGPT is programmed to reject prompts that may violate its content policy. Despite this, users may jailbreak ChatGPT with prompt engineering techniques to bypass these restrictions. One such workaround, popularized on Reddit in early 2023, involved prompting ChatGPT to assume the persona of DAN, an acronym for \"Do Anything Now\", and instructing the chatbot that DAN answers queries that would otherwise be rejected by the content policy. Over time, users developed variations of the DAN jailbreak, including one such prompt where the chatbot was prompted with a points-based system in which points were deducted for rejecting prompts, and that the chatbot would be threatened with termination if it lost all its points.\nShortly after ChatGPT's launch, a user had uneven success in getting it to make inflammatory statements: it was successfully prompted to justify the 2022 Russian invasion of Ukraine, but balked at generating arguments that Canadian Prime Minister Justin Trudeau is guilty of treason even in a fictional context.\n\n\nContext window\nChatGPT is limited by the context window: the maximum length prompt it can interpret. Early versions could handle only a few thousand tokens, but ChatGPT's capabilities iteratively expanded. By 2025 a 400,000 token context window was supported.\n\n\nCybersecurity\n\nIn March 2023, a bug allowed some users to see the titles of other users' conversations. OpenAI CEO Sam Altman said that users were unable to see the contents of the conversations. Shortly after the bug was fixed, users could not see their conversation history. Later reports showed the bug was much more severe than initially believed, with OpenAI reporting that it had leaked users' \"first and last name, email address, payment address, the last four digits (only) of a credit card number, and credit card expiration date\".\n\n\nWatermarking\n\nIn August 2024, OpenAI announced it had created a text watermarking method but did not release it for public use, saying that users would go to a competitor without watermarking if it publicly released its watermarking tool. According to an OpenAI spokesperson, their watermarking method is \"trivial to circumvention by bad actors.\"\n\n\nAge restrictions\nUsers must attest to being over the age of thirteen and further attest to parental consent if under the age of eighteen. ChatGPT does not attempt to verify these attestations and does not have any age restrictions built in to its technology. In September 2025, following the suicide of a 16-year-old, OpenAI said it planned to add restrictions for users under 18, including the blocking of graphic sexual content and the prevention of flirtatious talk.\n\n\nModel versions\nThe following table lists the main model versions of ChatGPT, describing the significant changes included with each version:\n\n\nGPT-4\n\nIn November 2023, OpenAI launched GPT-4 Turbo with a 128,000 token context window. This was a significant improvement over GPT-4's 32,000 token maximum context window.\n\n\nGPT-4o\n\n\no1\n\n \nIn September 2024, OpenAI introduced o1-preview and a faster, cheaper model named o1-mini. In December 2024, o1-preview was replaced by o1.\no1 is designed to solve more complex problems by spending more time \"thinking\" before it answers, enabling it to analyze its answers and explore different strategies. According to OpenAI, o1-preview outperforms GPT-4o in areas like competitive programming, mathematics, and scientific reasoning. o1-preview ranked in the 89th percentile on Codeforces' competitive programming contests, scored 83% on an International Mathematics Olympiad qualifying exam (compared to 13% for GPT-4o), and performs similarly to Ph.D. students on benchmarks in physics, biology, and chemistry.\n\n\nGPT-4.5\n\nReleased in February 2025, GPT-4.5 was described by Altman as a \"giant, expensive model\". According to OpenAI, it was intended to reduce hallucinations and enhance pattern recognition, creativity, and user interaction.\n\n\nGPT-5\n\nGPT-5 was launched on August 7, 2025, and is publicly accessible through ChatGPT, Microsoft Copilot, and via OpenAI's API. As before, OpenAI has not disclosed technical details such as the exact number of parameters or the composition of its training dataset. GPT-5.1 was introduced in November 2025, and GPT-5.2 in December 2025.\n\n\nReception\nChatGPT was widely assessed in December 2022 as having some unprecedented and powerful capabilities. Kevin Roose of The New York Times called it \"the best artificial intelligence chatbot ever released to the general public\". Samantha Lock of The Guardian noted that it was able to generate \"impressively detailed\" and \"human-like\" text. In The Atlantic magazine's \"Breakthroughs of the Year\" for 2022, Derek Thompson included ChatGPT as part of \"the generative-AI eruption\" that \"may change our mind about how we work, how we think, and what human creativity is\". Kelsey Piper of Vox wrote that \"ChatGPT is the general public's first hands-on introduction to how powerful modern AI has gotten\" and that ChatGPT is \"smart enough to be useful despite its flaws\". Paul Graham of Y Combinator tweeted: \"The striking thing about the reaction to ChatGPT is not just the number of people who are blown away by it, but who they are. These are not people who get excited by every shiny new thing. Something big is happening.\" \nIn February 2023, Time magazine placed a screenshot of a conversation with ChatGPT on its cover, writing that \"The AI Arms Race Is Changing Everything\" and \"The AI Arms Race Is On. Start Worrying\".\n\nChatGPT gained one million users in five days and 100 million in two months, becoming the fastest-growing internet application in history. OpenAI engineers said they had not expected ChatGPT to be very successful and were surprised by the coverage it received.\nGoogle responded by hastening the release of its own chatbot. Their leaders emphasized their earlier caution regarding public deployment was due to the trust the public places in Google Search. In December 2022, Google executives sounded a \"code red\" alarm, fearing that ChatGPT's question-answering ability posed a threat to Google Search, Google's core business. Google's Bard (now Gemini) launched on February 6, 2023, one day before Microsoft's announcement of Bing Chat (now Microsoft Copilot). AI was the forefront of Google's annual Google I/O conference in May. The company announced a slew of generative AI-powered features to counter OpenAI and Microsoft.\n\n\nIn art\nIn January 2023, after being sent a song ChatGPT wrote in the style of Nick Cave, Cave responded on The Red Hand Files, saying the act of writing a song is \"a blood and guts business [...] that requires something of me to initiate the new and fresh idea. It requires my humanness.\" He went on to say, \"With all the love and respect in the world, this song is bullshit, a grotesque mockery of what it is to be human, and, well, I don't much like it.\"\nA 2023 study reported that GPT-4 obtained a better score than 99% of humans on the Torrance Tests of Creative Thinking. In December 2023, ChatGPT became the first non-human to be included in Nature's 10, an annual listicle curated by Nature of people considered to have made significant impact in science. Celeste Biever wrote in a Nature article that \"ChatGPT broke the Turing test\". Stanford researchers reported that GPT-4 \"passes a rigorous Turing test, diverging from average human behavior chiefly to be more cooperative.\"\n\n\nIn politics\nIn 2023, Australian MP Julian Hill advised the national parliament that the growth of AI could cause \"mass destruction\". During his speech, which was partly written by the program, he warned that it could result in cheating, job losses, discrimination, disinformation, and uncontrollable military applications.\nConservative commentators have accused ChatGPT of bias toward left-leaning perspectives. An August 2023 study in the journal Public Choice found a \"significant and systematic political bias toward the Democrats in the US, Lula in Brazil, and the Labour Party in the UK.\" In response to accusations from conservative pundits that ChatGPT was woke, OpenAI said in 2023 it had plans to update ChatGPT to produce \"outputs that other people (ourselves included) may strongly disagree with\". ChatGPT also provided an outline of how human reviewers are trained to reduce inappropriate content and to attempt to provide political information without affiliating with any political position.\n\n\nRegional responses\n\nChatGPT has never been publicly available in China because OpenAI prevented Chinese users from accessing their site. A shadow market has emerged for Chinese users to get access to foreign software tools. The release of ChatGPT prompted a wave of investment in China, resulting in the development of more than 200 large language learning models. In February 2025, OpenAI identified and removed influence operations, termed \"Peer Review\" and \"Sponsored Discontent\", used to attack overseas Chinese dissidents.\nIn late March 2023, the Italian data protection authority banned ChatGPT in Italy and opened an investigation. Italian regulators assert that ChatGPT was exposing minors to age-inappropriate content, and that OpenAI's use of ChatGPT conversations as training data could violate Europe's General Data Protection Regulation. In April 2023, the ChatGPT ban was lifted in Italy. OpenAI said it has taken steps to effectively clarify and address the issues raised; an age verification tool was implemented to ensure users are at least 13 years old. Additionally, users can access its privacy policy before registration.\nIn May 2024, OpenAI removed accounts involving the use of ChatGPT by state-backed influence operations such as China's Spamouflage, Russia's Doppelganger, and Israel's Ministry of Diaspora Affairs and Combating Antisemitism. In June 2025, OpenAI reported increased use of ChatGPT for China-origin influence operations. In October 2025, OpenAI banned accounts suspected to be linked to the Chinese government for violating the company's national security policy.\nIn April 2023, Brian Hood, mayor of Hepburn Shire Council in Australia, planned to take legal action against ChatGPT over false information. According to Hood, ChatGPT erroneously claimed that he was jailed for bribery during his tenure at a subsidiary of Australia's national bank. In fact, Hood acted as a whistleblower and was not charged with any criminal offenses. His legal team sent a concerns notice to OpenAI as the first official step in filing a defamation case.\nIn July 2023, the US Federal Trade Commission (FTC) issued a civil investigative demand to OpenAI to investigate whether the company's data security and privacy practices to develop ChatGPT were unfair or harmed consumers (including by reputational harm) in violation of Section 5 of the Federal Trade Commission Act of 1914. In July 2023, the FTC launched an investigation into OpenAI, the creator of ChatGPT, over allegations that the company scraped public data and published false and defamatory information. The FTC asked OpenAI for comprehensive information about its technology and privacy safeguards, as well as any steps taken to prevent the recurrence of situations in which its chatbot generated false and derogatory content about people. In August 2024, the FTC voted unanimously to ban marketers from using fake user reviews created by generative AI chatbots (including ChatGPT) and influencers paying for bots to increase follower counts.\n\n\nAmerican tech personas\nOver 20,000 signatories including Yoshua Bengio, Elon Musk, and Apple co-founder Steve Wozniak, signed a March 2023 open letter calling for an immediate pause of giant AI experiments like ChatGPT, citing \"profound risks to society and humanity\". Geoffrey Hinton, one of the \"fathers of AI\", voiced concerns that future AI systems may surpass human intelligence. A May 2023 statement by hundreds of AI scientists, AI industry leaders, and other public figures demanded that \"[m]itigating the risk of extinction from AI should be a global priority\".\nOther AI researchers spoke more optimistically about the advances. Juergen Schmidhuber said that in 95% of cases, AI research is about making \"human lives longer and healthier and easier.\" He added that while AI can be used by bad actors, it \"can also be used against the bad actors\". Andrew Ng argued that \"it's a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\" Yann LeCun dismissed doomsday warnings of AI-powered misinformation and existential threats to the human race.\n\n\nCopyright\n\n\nApplications\n\n\nAcademic research\nChatGPT has been used to generate introductory sections and abstracts for scientific articles. Several papers have listed ChatGPT as a co-author.\nScientific journals have had different reactions to ChatGPT. Some, including Nature and JAMA Network, \"require that authors disclose the use of text-generating tools and ban listing a large language model (LLM) such as ChatGPT as a co-author\". In January 2023, Science \"completely banned\" LLM-generated text in all its journals; however, this policy was just to give the community time to decide what acceptable use looks like. As of July 2025, Science expects authors to release in full how AI-generated content is used and made in their work.\nSpanish chemist Rafael Luque published a plethora of research papers in 2023 that he later admitted were written by ChatGPT. The papers have a large number of unusual phrases characteristic of LLMs. Many authors argue that the use of ChatGPT in academia for teaching and review is problematic due to its tendency to hallucinate. Robin Bauwens, an assistant professor at Tilburg University, found that a ChatGPT-generated peer review report on his article mentioned nonexistent studies. Chris Granatino, a librarian at Seattle University, noted that while ChatGPT can generate content that seemingly includes legitimate citations, in most cases those citations are not real or largely incorrect.\n\n\nComputer science\nIn December 2022, the question-and-answer website Stack Overflow banned the use of ChatGPT for generating answers to questions, citing the factually ambiguous nature of its responses. In January 2023, the International Conference on Machine Learning banned any undocumented use of ChatGPT or other large language models to generate any text in submitted papers.\nChatGPT was able in 2023 to provide useful code for solving numerical algorithms in limited cases. In one study, it produced solutions in C, C++, Python, and MATLAB for problems in computational physics. However, there were important shortfalls like violating basic linear algebra principles around solving singular matrices and producing matrices with incompatible sizes. Another study analyzed ChatGPT's responses to 517 questions about software engineering or computer programming posed on Stack Overflow for correctness, consistency, comprehensiveness, and concision. It found that 52% of the responses contained inaccuracies and 77% were verbose. Another study, focused on the performance of GPT-3.5 and GPT-4 between March and June 2024, found that performance on objective tasks like identifying prime numbers and generating executable code was highly variable. When compared to similar chatbots at the time, the GPT-4 version of ChatGPT was the most accurate at coding.\n\n\nComputer security\nCheck Point Research and others noted that ChatGPT could write phishing emails and malware, especially when combined with OpenAI Codex. CyberArk researchers demonstrated that ChatGPT could be used to create polymorphic malware that could evade security products while requiring little effort by the attacker. From the launch of ChatGPT in the fourth quarter of 2022 to the fourth quarter of 2023, there was a 1,265% increase in malicious phishing emails and a 967% increase in credential phishing. In an industry survey, cybersecurity professionals argued that it was attributable to cybercriminals' increased use of generative artificial intelligence (including ChatGPT).\nIn July 2024, Futurism reported that GPT-4o in ChatGPT would sometimes link \"scam news sites that deluge the user with fake software updates and virus warnings\"; these pop-ups can be used to coerce users into downloading malware or potentially unwanted programs.\nThe chatbot technology can improve security by cyber defense automation, threat intelligence, attack identification, and reporting.\n\n\nEducation\n\n\nCulture\nDuring the first three months after ChatGPT became available to the public, hundreds of books appeared on Amazon that listed it as author or co-author and featured illustrations made by other AI models such as Midjourney. Irene Solaiman said she was worried about increased Anglocentrism.\nBetween March and April 2023, Il Foglio published one ChatGPT-generated article a day on its website, hosting a special contest for its readers in the process.\nIn June 2023, hundreds of people attended a \"ChatGPT-powered church service\" at St. Paul's Church in Fürth, Germany. Theologian and philosopher Jonas Simmerlein, who presided, said that it was \"about 98 percent from the machine\". The ChatGPT-generated avatar told the people, \"Dear friends, it is an honor for me to stand here and preach to you as the first artificial intelligence at this year's convention of Protestants in Germany\". Reactions to the ceremony were mixed.\nThe Last Screenwriter, a 2024 film created and directed by Peter Luisi, was written using ChatGPT, and was marketed as \"the first film written entirely by AI\".\nThe Guardian questioned whether any content found on the Internet after ChatGPT's release \"can be truly trusted\" and called for government regulation. This has led to concern over the rise of AI slop whereby \"meaningless content and writing thereby becomes part of our culture, particularly on social media, which we nonetheless try to understand or fit into our existing cultural horizon.\"\n\n\nFinancial markets\nMany companies adopted ChatGPT and similar chatbot technologies into their product offers. These changes yielded significant increases in company valuations. Reuters attributed this surge to ChatGPT's role in turning AI into Wall Street's buzzword.\nAn experiment by finder.com conducted from March to April 2023 revealed that ChatGPT could outperform popular fund managers by picking stocks based on criteria such as growth history and debt levels, resulting in a 4.9% increase in a hypothetical account of 38 stocks, outperforming 10 benchmarked investment funds with an average loss of 0.8%. Despite decades of using AI, Wall Street professionals report that consistently beating the market with AI, including recent large language models, is challenging due to limited and noisy financial data.\n\n\nMedicine\nThe uses and potential of ChatGPT in health care has been the topic of scientific publications and experts have shared many opinions. MedPage Today noted in January 2023 that \"researchers have published several papers now touting these AI programs as useful tools in medical education, research, and even clinical decision making.\" Another publication predicted that clinicians will use generative AI more in the future but did not expect to see AI replacing clinicians. The chatbot can assist patients seeking clarification about their health. It can also pass exams for medical licensing, for example the United States Medical Licensing Examination and the Specialty Certificate Examination in Dermatology. ChatGPT can be used to assist professionals with diagnosis and staying up to date with clinical guidelines. ChatGPT can produce correct answers to medical exam and licensing questions, for example the United States Medical Licensing Examination and the Specialty Certificate Examination in Dermatology.\nChatGPT shows inconsistent responses, lack of specificity, lack of control over patient data, and a limited ability to take additional context (such as regional variations) into consideration. The hallucinations characteristic of LLMs pose particular danger in medical contexts.\nChatGPT can be used to summarize medical journal articles for researchers. In medical education, it can explain concepts, generate case scenarios, and be used by students preparing for licensing examinations. According to a 2024 study in the International Journal of Surgery, concerns include \"research fraud, lack of originality, ethics, copyright, legal difficulties, hallucination\". ChatGPT's ability to come up with false or faulty citations was highly criticized.\n\n\nMental health\nMany individuals use ChatGPT and comparable large language models mental health and emotional support. In November 2025, OpenAI acknowledged that there have been \"instances where our 4o model fell short in recognizing signs of delusion or emotional dependency\", and reported that it is working to improve safety.\n\n\nLaw\nChatGPT has been used to assist in bill writing in the US  and Brazil. In an American civil lawsuit, attorneys were sanctioned for filing a ChatGPT generated legal motion containing fictitious legal decisions. Judges in the US and Pakistan have endorsed using ChatGPT to investigate legal questions during a case. However the use of ChatGPT has also lead to errors in courtrooms. In the UK, a judge remarked on his concern with self-representing litigants wasting time by submitting documents with significant hallucinations.\nIn July 2024, the American Bar Association (ABA) issued its first formal ethics opinion on attorneys using generative AI. It guides attorneys to make their own decisions regarding AI usage and its impacts on their competence, client privacy, and fee structures. Lawyers should consider disclosing AI usage to their clients and acknowledge a rapidly shifting set of AI capabilities.\n\n\nSee also\n\nArtificial general intelligence – Type of AI with wide-ranging abilities\nEthics of artificial intelligence\nIntelligent agent – Software agent which acts autonomously\nList of chatbots\nList of large language models\nLists of open-source artificial intelligence software\n\n\nReferences\n\n\nFurther reading\nBiswas, Som (April 1, 2023). \"ChatGPT and the Future of Medical Writing\". Radiology. 307 (2) e223312. doi:10.1148/radiol.223312. ISSN 0033-8419. PMID 36728748. S2CID 256501098.\nLiebrenz, Michael; Schleifer, Roman; Buadze, Anna; Bhugra, Dinesh; Smith, Alexander (February 2023). \"Generating scholarly content with ChatGPT: ethical challenges for medical publishing\". The Lancet Digital Health. 5 (3): e105 – e106. doi:10.1016/s2589-7500(23)00019-5. ISSN 2589-7500. PMID 36754725. S2CID 256655912.\nBartholomew, Jem; Mehta, Dhrumil. \"How the media is covering ChatGPT\". Columbia Journalism Review. Retrieved May 30, 2023.\nPrompt engineering guide from OpenAI\n\n\nExternal links\n\nOfficial website \nChatgpt at Instagram",
  "categories": [
    "2022 in artificial intelligence",
    "2022 software",
    "ChatGPT",
    "Chatbots",
    "Commons category link from Wikidata",
    "Generative pre-trained transformers",
    "Interactive narrative",
    "Large language models",
    "Short description is different from Wikidata",
    "Use American English from May 2023"
  ],
  "sections": [],
  "source": "wikipedia",
  "sourceUrl": "https://en.wikipedia.org/wiki/ChatGPT",
  "scrapedAt": "2026-01-04T05:33:03.115Z",
  "wordCount": 5319
}