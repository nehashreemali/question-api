{
  "title": "Laws of thermodynamics",
  "slug": "laws-of-thermodynamics",
  "extract": "The laws of thermodynamics are a set of scientific laws which define a group of physical quantities, such as temperature, energy, and entropy, that characterize thermodynamic systems in thermodynamic equilibrium. The laws also use various parameters for thermodynamic processes, such as thermodynamic work and heat, and establish relationships between them. They state empirical facts that form a basis of precluding the possibility of certain phenomena, such as perpetual motion. In addition to their use in thermodynamics, they are important fundamental laws of physics in general and are applicable in other natural sciences.\nTraditionally, thermodynamics has recognized three fundamental laws, simply named by an ordinal identification, the first law, the second law, and the third law. A more fundamental statement was later labelled as the zeroth law after the first three laws had been established.\nThe zeroth law of thermodynamics defines thermal equilibrium and forms a basis for the definition of temperature: if two systems are each in thermal equilibrium with a third system, then they are in thermal equilibrium with each other.\nThe first law of thermodynamics states that, when energy passes into or out of a system (as work, heat, or matter), the system's internal energy changes in accordance with the law of conservation of energy. This also results in the observation that, in an externally isolated system, even with internal changes, the sum of all forms of energy must remain constant, as energy cannot be created or destroyed. \nThe second law of thermodynamics states that in a natural thermodynamic process, the sum of the entropies of the interacting thermodynamic systems never decreases. A common corollary of the statement is that heat does not spontaneously pass from a colder body to a warmer body.\nThe third law of thermodynamics states that a system's entropy approaches a constant value as the temperature approaches absolute zero. With the exception of non-crystalline solids (glasses), the entropy of a system at absolute zero is typically close to zero.\nThe first and second laws prohibit two kinds of perpetual motion machines, respectively: the perpetual motion machine of the first kind which produces work with no energy input, and the perpetual motion machine of the second kind which spontaneously converts thermal energy into mechanical work.\n\n\nHistory\n\nThe history of thermodynamics is fundamentally interwoven with the history of physics and the history of chemistry, and ultimately dates back to theories of heat in antiquity. The laws of thermodynamics are the result of progress made in this field over the nineteenth and early twentieth centuries. The first established thermodynamic principle, which eventually became the second law of thermodynamics, was formulated by Sadi Carnot in 1824 in his book Reflections on the Motive Power of Fire. By 1860, as formalized in the works of scientists such as Rudolf Clausius and William Thomson, what are now known as the first and second laws were established. Later, Nernst's theorem (or Nernst's postulate), which is now known as the third law, was formulated by Walther Nernst over the period 1906–1912. While the numbering of the laws is universal today, various textbooks throughout the 20th century have numbered the laws differently.  In some fields, the second law was considered to deal with the efficiency of heat engines only, whereas what was called the third law dealt with entropy increases. Gradually, this resolved itself and a zeroth law was later added to allow for a self-consistent definition of temperature. Additional laws have been suggested, but have not achieved the generality of the four accepted laws, and are generally not discussed in standard textbooks.\n\n\nZeroth law\nThe zeroth law of thermodynamics provides for the foundation of temperature as an empirical parameter in thermodynamic systems and establishes the transitive relation between the temperatures of multiple bodies in thermal equilibrium. The law may be stated in the following form:\n\nIf two systems are both in thermal equilibrium with a third system, then they are in thermal equilibrium with each other.\nThough this version of the law is one of the most commonly stated versions, it is only one of a diversity of statements that are labeled as \"the zeroth law\". Some statements go further, so as to supply the important physical fact that temperature is one-dimensional and that one can conceptually arrange bodies in a real number sequence from colder to hotter.\nThese concepts of temperature and of thermal equilibrium are fundamental to thermodynamics and were clearly stated in the nineteenth century. The name 'zeroth law' was invented by Ralph H. Fowler in the 1930s, long after the first, second, and third laws were widely recognized. The law allows the definition of temperature in a non-circular way without reference to entropy, its conjugate variable. Such a temperature definition is said to be 'empirical'.\n\n\nFirst law\n\nThe first law of thermodynamics is a version of the law of conservation of energy, adapted for thermodynamic processes. In general, the conservation law states that the total energy of an isolated system is constant; energy can be transformed from one form to another, but can be neither created nor destroyed.\n\nIn a closed system (i.e. there is no transfer of matter into or out of the system), the first law states that the change in internal energy of the system (ΔUsystem) is equal to the difference between the heat supplied to the system (Q) and the work (W) done by the system on its surroundings. (Note, an alternate sign convention, not used in this article, is to define W as the work done on the system by its surroundings): \n  \n    \n      \n        Δ\n        \n          U\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n        =\n        Q\n        −\n        W\n        .\n      \n    \n    {\\displaystyle \\Delta U_{\\rm {system}}=Q-W.}\n  \n\nFor processes that include the transfer of matter, a further statement is needed.\n\nWhen two initially isolated systems are combined into a new system, then the total internal energy of the new system, Usystem, will be equal to the sum of the internal energies of the two initial systems, U1 and U2: \n  \n    \n      \n        \n          U\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n        =\n        \n          U\n          \n            1\n          \n        \n        +\n        \n          U\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle U_{\\rm {system}}=U_{1}+U_{2}.}\n  \n\nThe First Law encompasses several principles:\n\nConservation of energy, which says that energy can be neither created nor destroyed, but can only change form. A particular consequence of this is that the total energy of an isolated system does not change.\nThe concept of internal energy and its relationship to temperature. If a system has a definite temperature, then its total energy has three distinguishable components, termed kinetic energy (energy due to the motion of the system as a whole), potential energy (energy resulting from an externally imposed force field), and internal energy. The establishment of the concept of internal energy distinguishes the first law of thermodynamics from the more general law of conservation of energy. \n  \n    \n      \n        \n          E\n          \n            \n              t\n              o\n              t\n              a\n              l\n            \n          \n        \n        =\n        K\n        \n          E\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n        +\n        P\n        \n          E\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n        +\n        \n          U\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n      \n    \n    {\\displaystyle E_{\\rm {total}}=KE_{\\rm {system}}+PE_{\\rm {system}}+U_{\\rm {system}}}\n  \n\nWork is a process of transferring energy to or from a system in ways that can be described by macroscopic mechanical forces acting between the system and its surroundings. The work done by the system can come from its overall kinetic energy, from its overall potential energy, or from its internal energy. For example, when a machine (not a part of the system) lifts a system upwards, some energy is transferred from the machine to the system. The system's energy increases as work is done on the system and in this particular case, the energy increase of the system is manifested as an increase in the system's gravitational potential energy. Work added to the system increases the potential energy of the system.\nWhen matter is transferred into a system, the internal energy and potential energy associated with it are transferred into the new combined system. \n  \n    \n      \n        \n          \n            (\n            \n              u\n              \n              Δ\n              M\n            \n            )\n          \n          \n            \n              i\n              n\n            \n          \n        \n        =\n        Δ\n        \n          U\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n      \n    \n    {\\displaystyle \\left(u\\,\\Delta M\\right)_{\\rm {in}}=\\Delta U_{\\rm {system}}}\n  \n where u denotes the internal energy per unit mass of the transferred matter, as measured while in the surroundings; and ΔM denotes the amount of transferred mass.\nThe flow of heat is a form of energy transfer. Heat transfer is the natural process of moving energy to or from a system, other than by work or the transfer of matter. In a diathermal system, the internal energy can only be changed by the transfer of energy as heat: \n  \n    \n      \n        Δ\n        \n          U\n          \n            \n              s\n              y\n              s\n              t\n              e\n              m\n            \n          \n        \n        =\n        Q\n        .\n      \n    \n    {\\displaystyle \\Delta U_{\\rm {system}}=Q.}\n  \n\nCombining these principles leads to one traditional statement of the first law of thermodynamics: it is not possible to construct a machine which will perpetually output work without an equal amount of energy input to that machine. Or more briefly, a perpetual motion machine of the first kind is impossible.\n\n\nSecond law\nThe second law of thermodynamics indicates the irreversibility of natural processes, and in many cases, the tendency of natural processes to lead towards spatial homogeneity of matter and energy, especially of temperature. It can be formulated in a variety of interesting and important ways. One of the simplest is the Clausius statement, that heat does not spontaneously pass from a colder to a hotter body.\nIt implies the existence of a quantity called the entropy of a thermodynamic system. In terms of this quantity it implies that\n\nWhen two initially isolated systems in separate but nearby regions of space, each in thermodynamic equilibrium with itself but not necessarily with each other, are then allowed to interact, they will eventually reach a mutual thermodynamic equilibrium. The sum of the entropies of the initially isolated systems is less than or equal to the total entropy of the final combination. Equality occurs just when the two original systems have all their respective intensive variables (temperature, pressure) equal; then the final system also has the same values.\nThe second law is applicable to a wide variety of processes, both reversible and irreversible. According to the second law, in a reversible heat transfer, an element of heat transferred, \n  \n    \n      \n        δ\n        Q\n      \n    \n    {\\displaystyle \\delta Q}\n  \n, is the product of the temperature (\n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  \n), both of the system and of the sources or destination of the heat, with the increment (\n  \n    \n      \n        d\n        S\n      \n    \n    {\\displaystyle dS}\n  \n) of the system's conjugate variable, its entropy (\n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n):\n\n  \n    \n      \n        δ\n        Q\n        =\n        T\n        \n        d\n        S\n        \n        .\n      \n    \n    {\\displaystyle \\delta Q=T\\,dS\\,.}\n  \n\nWhile reversible processes are a useful and convenient theoretical limiting case, all natural processes are irreversible. A prime example of this irreversibility is the transfer of heat by conduction or radiation. It was known long before the discovery of the notion of entropy that when two bodies, initially of different temperatures, come into direct thermal connection, then heat immediately and spontaneously flows from the hotter body to the colder one.\nEntropy may also be viewed as a physical measure concerning the microscopic details of the motion and configuration of a system, when only the macroscopic states are known. Such details are often referred to as disorder on a microscopic or molecular scale, and less often as dispersal of energy. For two given macroscopically specified states of a system, there is a mathematically defined quantity called the 'difference of information entropy between them'. This defines how much additional microscopic physical information is needed to specify one of the macroscopically specified states, given the macroscopic specification of the other – often a conveniently chosen reference state which may be presupposed to exist rather than explicitly stated. A final condition of a natural process always contains microscopically specifiable effects which are not fully and exactly predictable from the macroscopic specification of the initial condition of the process. This is why entropy increases in natural processes – the increase tells how much extra microscopic information is needed to distinguish the initial macroscopically specified state from the final macroscopically specified state. Equivalently, in a thermodynamic process, energy spreads.\n\n\nThird law\nThe third law of thermodynamics can be stated as:\n\nA system's entropy approaches a constant value as its temperature approaches absolute zero.\n\nAt absolute zero temperature, the system is in the state with the minimum thermal energy, the ground state. The constant value (not necessarily zero) of entropy at this point is called the residual entropy of the system. With the exception of non-crystalline solids (e.g. glass) the residual entropy of a system is typically close to zero. However, it reaches zero only when the system has a unique ground state (i.e., the state with the minimum thermal energy has only one configuration, or microstate). Microstates are used here to describe the probability of a system being in a specific state, as each microstate is assumed to have the same probability of occurring, so macroscopic states with fewer microstates are less probable. In general, entropy is related to the number of possible microstates according to the Boltzmann principle\n\n  \n    \n      \n        S\n        =\n        \n          k\n          \n            \n              B\n            \n          \n        \n        \n        \n          l\n          n\n        \n        \n        Ω\n      \n    \n    {\\displaystyle S=k_{\\mathrm {B} }\\,\\mathrm {ln} \\,\\Omega }\n  \n\nwhere S is the entropy of the system, kB is the Boltzmann constant, and Ω the number of microstates. At absolute zero there is only 1 microstate possible (Ω = 1 as all the atoms are identical for a pure substance, and as a result all orders are identical as there is only one combination) and \n  \n    \n      \n        ln\n        ⁡\n        (\n        1\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\ln(1)=0}\n  \n.\n\n\nOnsager relations\n\nThe Onsager reciprocal relations have been considered the fourth law of thermodynamics. They describe the relation between thermodynamic flows and forces in non-equilibrium thermodynamics, under the assumption that thermodynamic variables can be defined locally in a condition of local equilibrium. These relations are derived from statistical mechanics under the principle of microscopic reversibility (in the absence of external magnetic fields). Given a set of extensive parameters  Xi  (energy, mass, entropy, number of particles and so on) and thermodynamic forces  Fi  (related to their related intrinsic parameters, such as temperature and pressure), the Onsager theorem states that\n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              \n                J\n                \n                  k\n                \n              \n            \n            \n              \n                d\n              \n              \n                F\n                \n                  i\n                \n              \n            \n          \n        \n        \n          \n            \n              |\n            \n          \n          \n            \n              F\n              \n                i\n              \n            \n            =\n            0\n          \n        \n         \n        =\n         \n        \n          \n            \n              \n                d\n              \n              \n                J\n                \n                  i\n                \n              \n            \n            \n              \n                d\n              \n              \n                F\n                \n                  k\n                \n              \n            \n          \n        \n        \n          \n            \n              |\n            \n          \n          \n            \n              F\n              \n                k\n              \n            \n            =\n            0\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} J_{k}}{\\mathrm {d} F_{i}}}{\\bigg |}_{F_{i}=0}~=~{\\frac {\\mathrm {d} J_{i}}{\\mathrm {d} F_{k}}}{\\bigg |}_{F_{k}=0}}\n  \n\nwhere i, k = 1,2,3,... index every parameter and its related force, and\n\n  \n    \n      \n        \n          J\n          \n            i\n          \n        \n        =\n        \n          \n            \n              \n                d\n              \n              \n                X\n                \n                  i\n                \n              \n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n      \n    \n    {\\displaystyle J_{i}={\\frac {\\mathrm {d} X_{i}}{\\mathrm {d} t}}}\n  \n\nare called the thermodynamic flows.\n\n\nSee also\nBlack hole thermodynamics\nChemical thermodynamics\nEnthalpy\nEntropy production\nGinsberg's theorem (Parody of the laws of thermodynamics)\nH-theorem\nStatistical mechanics\nTable of thermodynamic equations\n\n\nReferences\n\n\nFurther reading\nAtkins, Peter (2007). Four Laws That Drive the Universe. OUP Oxford. ISBN 978-0199232369\nGoldstein, Martin & Inge F. (1993). The Refrigerator and the Universe. Harvard Univ. Press. ISBN 978-0674753259\nGuggenheim, E.A. (1985). Thermodynamics. An Advanced Treatment for Chemists and Physicists, seventh edition. ISBN 0-444-86951-4\nAdkins, C. J., (1968) Equilibrium Thermodynamics. McGraw-Hill ISBN 0-07-084057-1\n\n\nExternal links\n Media related to Laws of thermodynamics at Wikimedia Commons",
  "categories": [
    "Commons category link from Wikidata",
    "Laws of thermodynamics",
    "Scientific laws",
    "Short description is different from Wikidata"
  ],
  "sections": [],
  "source": "wikipedia",
  "sourceUrl": "https://en.wikipedia.org/wiki/Laws_of_thermodynamics",
  "scrapedAt": "2026-01-04T04:40:05.437Z",
  "wordCount": 2488
}